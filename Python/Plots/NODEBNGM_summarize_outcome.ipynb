{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize outcomes of NODEBNGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import re\n",
    "import math\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "from plot_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load folder directory of batch\n",
    "datasets = [\n",
    "    'miaSim',\n",
    "    'miaSim_noise_0-005',\n",
    "    'miaSim_noise_0-01',\n",
    "    'miaSim_noise_0-02',\n",
    "    'miaSim_noise_0-04'.\n",
    "    '3DLV',\n",
    "    'VanderPol',\n",
    "    'VanderPol_noise_0-1',\n",
    "    'VanderPol_noise_0-2',\n",
    "    'VanderPol_noise_0-5',\n",
    "    'VanderPol_noise_1',\n",
    "    'donorA_ALR',\n",
    "    'donorB_ALR',\n",
    "    'male_ALR',\n",
    "    'female_ALR', \n",
    "    'Silverman_all_ALR',\n",
    "    'Silverman_daily_ALR',\n",
    "    'Silverman_hourly_ALR',\n",
    "    'Bucci_ALR',\n",
    "    'BioTIME_study_339_Genus_10',\n",
    "    'BioTIME_study_339_Species_15',\n",
    "    'BioTIME_study_363_Genus_10',\n",
    "    'BioTIME_study_363_Species_15',\n",
    "    'BioTIME_study_39_Genus_10',\n",
    "    'BioTIME_study_39_Species_15',\n",
    "    'BioTIME_study_478_Genus_10',\n",
    "    'BioTIME_study_478_Species_15',\n",
    "    'Ushio'\n",
    "    ]\n",
    "\n",
    "output_dir_raw = f\"C:/Users/Maria/Documents/Masterstudium/Masterarbeit/MScThesis/R/NODEBNGM/output/\"\n",
    "\n",
    "data_dir_comp = \"C:/Users/Maria/Documents/Masterstudium/Masterarbeit/MScThesis/Python/ALR_transformation/ALR_transformed_data/\"\n",
    "data_dir_absolute = \"C:/Users/Maria/Documents/Masterstudium/Masterarbeit/MScThesis/explore/data/final_datasets/\"\n",
    "\n",
    "# create color map and load color palette for plots\n",
    "cmap = LinearSegmentedColormap.from_list(\"white_to_green\", [\"white\", \"darkgreen\"])\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Calculate weighted effects matrix for all runs\n",
    "weighted effects = (sign(effects)*weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    # dataset = \"female_ALR\"\n",
    "    out_dir = output_dir_raw + \"out_\" + dataset + \"/\"\n",
    "\n",
    "    # get list of available runs for the given dataset\n",
    "    runs = []\n",
    "    for file in [s for s in os.listdir(out_dir) if dataset in s]:\n",
    "        runs.append(file)\n",
    "\n",
    "    # specify dimensions of the plot\n",
    "    n_runs = len(runs)\n",
    "\n",
    "    # check if runs for these specifications are available\n",
    "    if n_runs > 0:\n",
    "        for run in runs:\n",
    "            out_run = out_dir + run\n",
    "            \n",
    "            if os.path.exists(f\"{out_run}/effectsMat.csv\"):\n",
    "                # read data files\n",
    "                df_effects_tmp = pd.read_csv(f\"{out_run}/effectsMat.csv\", header=[0])\n",
    "                df_weights_tmp = pd.read_csv(f\"{out_run}/weightsMat.csv\", header=[0])\n",
    "                n_taxa = df_effects_tmp.shape[0]\n",
    "\n",
    "                # load and save sign of effectsMat\n",
    "                df_effects_sign_tmp = np.sign(df_effects_tmp)\n",
    "                df_effects_sign_tmp.to_csv(f'{out_run}/effectsMat_sign.csv', index=False)\n",
    "\n",
    "                # calculate weighted effects\n",
    "                df_weighted_effects_tmp = df_effects_sign_tmp * df_weights_tmp\n",
    "                df_weighted_effects_tmp.to_csv(f'{out_run}/weighted_effectsMat.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Create summary plots containing all plots of all runs for one dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize all heatmaps of interaction matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miaSim_noise_0-005\n",
      "miaSim_noise_0-01\n",
      "miaSim_noise_0-02\n",
      "miaSim_noise_0-04\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    # dataset = datasets[10]\n",
    "    print(dataset)\n",
    "    Mat = \"weighted_effectsMat\" # \"effectsMat\", \"weightsMat\"\n",
    "    # dataset = datasets[1]\n",
    "    out_dir = output_dir_raw + \"out_\" + dataset + \"/\"\n",
    "\n",
    "    # get list of available runs for the given dataset\n",
    "    runs = []\n",
    "    for file in [s for s in os.listdir(out_dir) if dataset in s]:\n",
    "        m = re.search(r\"run(\\d{2})\", file)\n",
    "        if m:\n",
    "            runs.append(m.group(1))\n",
    "\n",
    "    # specify dimensions of the plot\n",
    "    n_runs = len(runs)\n",
    "\n",
    "    # check if runs for these specifications are available\n",
    "    if n_runs > 0 and n_runs < 10:\n",
    "        # specify dimensions of the plot\n",
    "        n_row = 3\n",
    "        n_col = 3\n",
    "\n",
    "        # make plot\n",
    "        fig, axs = plt.subplots(n_row, n_col)\n",
    "        # fig.set_figwidth(4*n_col)\n",
    "        # fig.set_figheight(2*n_row)\n",
    "        fig.suptitle(f'{dataset}, {Mat}', y=1.0, fontsize = 20)\n",
    "\n",
    "        y = 0\n",
    "\n",
    "        for run in runs:\n",
    "            out_run = out_dir + \"out_\" + dataset + f\"_run{run}\"\n",
    "            # print(out_run)\n",
    "            \n",
    "            if os.path.exists(f\"{out_run}/{Mat}.csv\"):\n",
    "                # read data files\n",
    "                df_model_coeffs_tmp = pd.read_csv(f\"{out_run}/{Mat}.csv\", header=[0])\n",
    "                n_taxa = df_model_coeffs_tmp.shape[0]\n",
    "                \n",
    "                fig.set_figwidth(max(math.ceil(20/n_taxa), 4) * n_taxa)\n",
    "                fig.set_figheight(max(math.ceil(15/n_taxa), 3) * n_taxa)\n",
    "                # Decrease the distance between subplots\n",
    "                fig.tight_layout(pad=1.0, w_pad=0.1, h_pad=0.1)\n",
    "\n",
    "                # make heatmap\n",
    "                if Mat == \"weightsMat\": # scale colors only for positive values\n",
    "                    sns.heatmap(round(df_model_coeffs_tmp,2), annot=True, fmt=\"\", cmap=cmap, vmin=0, ax=axs[int(y/n_col), y%n_col],\n",
    "                            xticklabels=False)\n",
    "                else:\n",
    "                    sns.heatmap(round(df_model_coeffs_tmp,2), annot=True, fmt=\"\", cmap=\"vlag\", center=0, ax=axs[int(y/n_col), y%n_col],\n",
    "                            xticklabels=False)\n",
    "                    \n",
    "                axs[int(y/n_col), y%n_col].xaxis.tick_top()\n",
    "                axs[int(y/n_col), y%n_col].set_title(f\"run{run}\")\n",
    "                y += 1\n",
    "\n",
    "        fig.tight_layout(pad=1.0)\n",
    "        plt.yticks(rotation=0)\n",
    "\n",
    "        # save plot\n",
    "        plt.savefig(f'{out_dir}/summary_{Mat}_heatmap.pdf',\n",
    "                    bbox_inches='tight', dpi = 300)\n",
    "        plt.close()\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize all fits in one plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miaSim_noise_0-005\n",
      "miaSim_noise_0-01\n",
      "miaSim_noise_0-02\n",
      "miaSim_noise_0-04\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    # dataset = datasets[0]\n",
    "    print(dataset)\n",
    "    out_dir = output_dir_raw + \"out_\" + dataset + \"/\"\n",
    "\n",
    "    # get number of taxa\n",
    "    df = pd.read_csv(f'{out_dir}/out_{dataset}_run05/Names_xi.csv')\n",
    "    n_taxa = len(df.index)\n",
    "\n",
    "    # get list of available runs for the given dataset\n",
    "    runs = []\n",
    "    for file in [s for s in os.listdir(out_dir) if dataset[0] in s]:\n",
    "        m = re.search(r\"run(\\d{2})\", file)\n",
    "        if m:\n",
    "            runs.append(m.group(1))\n",
    "\n",
    "    # specify dimensions of the plot\n",
    "    n_runs = len(runs)\n",
    "\n",
    "    # check if runs for these specifications are available\n",
    "    if n_runs > 0 and n_runs < 10:\n",
    "\n",
    "        # specify dimensions of the plot\n",
    "        n_row = n_runs\n",
    "        n_col = n_taxa\n",
    "\n",
    "        # make plot\n",
    "        fig, axs = plt.subplots(n_row, n_col)\n",
    "        fig.set_figwidth(3.5*n_col)\n",
    "        fig.set_figheight(2*n_row)\n",
    "        fig.suptitle(dataset, y=1.0, fontsize = 16)\n",
    "        fig.tight_layout(pad = 2)\n",
    "\n",
    "        y = 0\n",
    "\n",
    "        for run in runs:\n",
    "            out_run = out_dir + \"out_\" + dataset + f\"_run{run}\"\n",
    "            \n",
    "            if os.path.exists(f\"{out_run}/{Mat}.csv\"):\n",
    "                # read data files\n",
    "                df_pred = pd.read_csv(f\"{out_run}/Yhat.csv\", header=[0])\n",
    "                df_data_obs = pd.read_csv(f\"{out_run}/TS_{dataset}.csv\", header=[0])\n",
    "\n",
    "                # convert files to numpy array\n",
    "                data_obs = np.array(df_data_obs)\n",
    "                pred = np.array(df_pred)\n",
    "\n",
    "                for taxon in np.arange(n_taxa):\n",
    "                    # make plot\n",
    "                    axs[int(y/n_col), (taxon)].plot(data_obs[:,0], pred[:,(taxon)], label = \"fit\")\n",
    "                    axs[int(y/n_col), (taxon)].plot(data_obs[:,0], data_obs[:,(taxon+1)], label = \"data\", linewidth = 0.7, linestyle = '--', color = colors[1])\n",
    "                    axs[int(y/n_col), (taxon)].set_title(df_data_obs.columns[(taxon+1)])\n",
    "                    \n",
    "                    y += 1\n",
    "                axs[int((y-n_taxa)/n_col), 0].annotate(f\"run {run}\", xy=(0, 0.5), \n",
    "                                                    xytext=(-axs[int((y-n_taxa)/n_col), 0].yaxis.labelpad - 5, 0),\n",
    "                                                    xycoords=axs[int((y-n_taxa)/n_col), 0].yaxis.label, textcoords='offset points',\n",
    "                                                    size='large', ha='right', va='center')\n",
    "                \n",
    "                # add one legend for all polts (in the lower center)\n",
    "                handles, labels = axs[0,0].get_legend_handles_labels()\n",
    "                fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.03),\n",
    "                            fancybox=True, shadow=False, ncol = 4, fontsize = 12)\n",
    "        # save plots in one file\n",
    "        plt.savefig(f'{out_dir}/summary_prediction_fits.pdf',\n",
    "                    bbox_inches='tight', dpi = 300)\n",
    "        # save plots in one file\n",
    "        plt.savefig(f'{out_dir}/summary_prediction_fits.png',\n",
    "                    bbox_inches='tight', dpi = 300)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Calculate mean over effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean over all weightsMats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miaSim_noise_0-005\n",
      "miaSim_noise_0-01\n",
      "miaSim_noise_0-02\n",
      "miaSim_noise_0-04\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    # dataset = datasets[1]\n",
    "    print(dataset)\n",
    "    for Mat in [\"weightsMat\", \"weighted_effectsMat\"]: # \"effectsMat\", \"weightsMat\"\n",
    "        # Mat = \"weightsMat\"\n",
    "\n",
    "        out_dir = output_dir_raw + \"out_\" + dataset\n",
    "\n",
    "        # get number of taxa\n",
    "        df = pd.read_csv(f'{out_dir}/out_{dataset}_run05/Names_xi.csv')\n",
    "        n_taxa = len(df.index)\n",
    "\n",
    "        # get list of available runs for the given dataset\n",
    "        runs = []\n",
    "        for file in [s for s in os.listdir(out_dir) if dataset in s and \".\" not in s]:\n",
    "            runs.append(file)\n",
    "\n",
    "        # number of available runs\n",
    "        n_runs = len(runs)\n",
    "\n",
    "        # check if runs for these specifications are available\n",
    "        if n_runs > 0:\n",
    "            \n",
    "            df_model_coeffs_all = []\n",
    "            count = 0\n",
    "\n",
    "            for run in runs:\n",
    "                # run_nr = re.search(r\"run(\\d{2})\", run).group(1)\n",
    "                out_run = out_dir + \"/\" + run\n",
    "                if os.path.exists(f\"{out_run}/{Mat}.csv\"):\n",
    "                    df_model_coeffs_tmp = pd.read_csv(f\"{out_run}/{Mat}.csv\", header=[0])\n",
    "                    # print(df_model_coeffs_tmp)\n",
    "                    df_model_coeffs_all.append(df_model_coeffs_tmp.to_numpy())\n",
    "        \n",
    "        if len(df_model_coeffs_all) > 0:\n",
    "            # calculate mean over all coeff matrices\n",
    "            mean_array = np.mean(df_model_coeffs_all, axis=0)\n",
    "            # and save as csv file\n",
    "            pd.DataFrame(mean_array).to_csv(f'{out_dir}/weighted_effectsMat_mean.csv', index=False)\n",
    "            \n",
    "            # make plot\n",
    "            fig, ax = plt.subplots()\n",
    "            plot_heatmap(matrix_A = np.around(mean_array, 2), n_taxa = n_taxa, ax = ax, fig=fig,\n",
    "                        title = f\"{dataset}, mean over {Mat}\", colnames=df_model_coeffs_tmp.columns,\n",
    "                        Mat=Mat)\n",
    "            \n",
    "            # save plot\n",
    "            plt.savefig(f'{out_dir}/mean_{Mat}_heatmap.pdf',\n",
    "                        bbox_inches='tight', dpi = 300)\n",
    "            plt.close()\n",
    "            # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count times of effect > 0 in each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 9 8 4]\n",
      " [7 9 6 7]\n",
      " [4 2 9 9]\n",
      " [8 3 9 7]]\n"
     ]
    }
   ],
   "source": [
    "# Count the non-zero occurrences for each cell\n",
    "non_zero_counts = np.count_nonzero(df_model_coeffs_all, axis=0)\n",
    "\n",
    "print(non_zero_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
